{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SqueezeNet\n",
    "\n",
    "Described here: https://towardsdatascience.com/review-squeezenet-image-classification-e7414825581a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Concatenate, GlobalAveragePooling2D, Activation\n",
    "from tensorflow.keras.models import Model, save_model\n",
    "from tensorflow.keras.utils import plot_model, to_categorical\n",
    "import tensorflow_model_optimization as tfmot\n",
    "import requests\n",
    "import os\n",
    "import json\n",
    "import librosa\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import audiomentations as AA\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "url = \"https://xeno-canto.org/api/2/recordings?query=cnt:%22United%20States%22\"  # Replace with the actual URL\n",
    "\n",
    "# Function to process each recording object\n",
    "def process_recording(recording):\n",
    "    return {\n",
    "        'genus': recording['gen'],\n",
    "        'species': recording['sp'],\n",
    "        'name': recording['en'],\n",
    "        'file': recording['file']\n",
    "    }\n",
    "\n",
    "def fetch_data():\n",
    "    page = 1\n",
    "    results = []\n",
    "\n",
    "    while True:\n",
    "        response = requests.get(url, params={\"page\": page})\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            num_pages = int(data[\"numPages\"])\n",
    "            recordings = data[\"recordings\"]\n",
    "\n",
    "            # Process each recording object\n",
    "            results.extend([{\n",
    "                'genus': recording['gen'],\n",
    "                'species': recording['sp'],\n",
    "                'name': recording['en'],\n",
    "                'file': recording['file'],\n",
    "                'filename': recording['file-name']\n",
    "            } for recording in recordings])\n",
    "\n",
    "            if page == 3: #num_pages:\n",
    "                break  # Exit the loop if all pages have been fetched\n",
    "\n",
    "            page += 1  # Increment page for the next request\n",
    "        else:\n",
    "            print(\"Error:\", response.status_code)\n",
    "            break  # Stop fetching data in case of an error\n",
    "    return results\n",
    "\n",
    "call_recordings = fetch_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'XC371329-CANV_2017-04-16_Mitten_Lake_Blackfeet_Res_MT_1023(2).mp3' downloaded successfully.\n",
      "Metadata file 'XC371329-CANV_2017-04-16_Mitten_Lake_Blackfeet_Res_MT_1023(2).mp3.json' saved successfully.\n",
      "File 'XC169327-CANVASBACK Delran NJ 9.02am 03082014 (2).mp3' downloaded successfully.\n",
      "Metadata file 'XC169327-CANVASBACK Delran NJ 9.02am 03082014 (2).mp3.json' saved successfully.\n"
     ]
    }
   ],
   "source": [
    "def download_files(results, subdirectory):\n",
    "    os.makedirs(subdirectory, exist_ok=True)  # Create subdirectory if it doesn't exist\n",
    "\n",
    "    for result in results:\n",
    "        file_url = result['file']\n",
    "        filename = result['filename']\n",
    "        file_path = os.path.join(subdirectory, filename)  # Construct the file path\n",
    "\n",
    "        file = Path(file_path)\n",
    "        if file.is_file():\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # Download and save the file\n",
    "            response = requests.get(file_url)\n",
    "            if response.status_code == 200:\n",
    "                with open(file_path, 'wb') as file:\n",
    "                    file.write(response.content)\n",
    "                    print(f\"File '{filename}' downloaded successfully.\")\n",
    "            else:\n",
    "                print(f\"Failed to download file '{filename}'. Status code: {response.status_code}\")\n",
    "                continue\n",
    "        except Exception as e:\n",
    "            print(f\"Exception while attempting to download file '{filename}'. Exception: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Save metadata as a separate JSON file\n",
    "        metadata_filename = f\"{filename}.json\"\n",
    "        metadata_path = os.path.join(subdirectory, metadata_filename)\n",
    "        with open(metadata_path, 'w') as metadata_file:\n",
    "            json.dump(result, metadata_file, indent=4)\n",
    "            print(f\"Metadata file '{metadata_filename}' saved successfully.\")\n",
    "\n",
    "\n",
    "download_files(call_recordings, 'calls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(directory, test_size=0.2, random_state=42):\n",
    "    filenames = []\n",
    "    labels = []\n",
    "\n",
    "    target_size = (128, 512)\n",
    "    \n",
    "    # Load filenames and labels from metadata JSON files\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.json'):\n",
    "            with open(os.path.join(directory, filename)) as metadata_file:\n",
    "                metadata = json.load(metadata_file)\n",
    "                filenames.append(metadata['filename'])\n",
    "                labels.append(f\"{metadata['genus']} {metadata['species']}\")\n",
    "    \n",
    "    # Load and process audio files into MFCCs with data augmentation \n",
    "    mfccs = []\n",
    "    augmentation = AA.Compose([\n",
    "        AA.AddGaussianNoise(p=0.5),\n",
    "        AA.PitchShift(p=0.5),\n",
    "        AA.TimeStretch(p=0.5),\n",
    "        AA.Shift(p=0.5),\n",
    "        AA.Normalize(),\n",
    "    ])\n",
    "\n",
    "    # Encode labels to integers\n",
    "    label_encoder = LabelEncoder()\n",
    "    encoded_labels = label_encoder.fit_transform(labels)\n",
    "    \n",
    "    for filename in filenames:\n",
    "        audio_path = os.path.join(directory, filename)\n",
    "        y, sr = librosa.load(audio_path)\n",
    "        \n",
    "        # Apply data augmentation\n",
    "        #augmented_y = augmentation(samples=y, sample_rate=sr)   # this is about 1.75x longer, don't know if it's necessary\n",
    "        augmented_y = y\n",
    "        \n",
    "        # Compute MFCCs\n",
    "        mfcc =librosa.power_to_db(librosa.feature.melspectrogram(\n",
    "            np.float32(augmented_y), sr=sr, n_fft=2048, hop_length=512, n_mels=128), ref=np.max)\n",
    "        mfcc = Image.fromarray(mfcc).resize(target_size)\n",
    "        mfccs.append(mfcc)\n",
    "    \n",
    "    mfccs = np.stack(mfccs)\n",
    "    # Split the data into training and test datasets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(mfccs, encoded_labels, test_size=test_size, random_state=random_state)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, label_encoder\n",
    "\n",
    "X_train, X_test, y_train, y_test, label_encoder = load_data('calls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the figure\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(nrows=2, ncols=2)\n",
    "ax1.imshow(np.swapaxes(X_train[0], 0 ,1), interpolation='nearest', cmap=cm.viridis, origin='lower', aspect='auto')\n",
    "ax1.set_title(label_encoder.inverse_transform([y_train[0]])[0], {'fontsize':20, 'fontweight':'bold'})\n",
    "ax1.set_ylim(ax1.get_ylim()[::-1])\n",
    "ax2.imshow(np.swapaxes(X_train[1], 0 ,1), interpolation='nearest', cmap=cm.viridis, origin='lower', aspect='auto')\n",
    "ax2.set_title(label_encoder.inverse_transform([y_train[1]])[0], {'fontsize':20, 'fontweight':'bold'})\n",
    "ax2.set_ylim(ax2.get_ylim()[::-1])\n",
    "ax3.imshow(np.swapaxes(X_train[2], 0 ,1), interpolation='nearest', cmap=cm.viridis, origin='lower', aspect='auto')\n",
    "ax3.set_title(label_encoder.inverse_transform([y_train[2]])[0], {'fontsize':20, 'fontweight':'bold'})\n",
    "ax3.set_ylim(ax3.get_ylim()[::-1])\n",
    "ax4.imshow(np.swapaxes(X_train[3], 0 ,1), interpolation='nearest', cmap=cm.viridis, origin='lower', aspect='auto')\n",
    "ax4.set_title(label_encoder.inverse_transform([y_train[3]])[0], {'fontsize':20, 'fontweight':'bold'})\n",
    "ax4.set_ylim(ax4.get_ylim()[::-1])\n",
    "fig.set_size_inches(18,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fire_module(x, fire_id, squeeze=16, expand=64):\n",
    "    f_id = 'fire' + str(fire_id) + '/'\n",
    "\n",
    "    # Squeeze\n",
    "    x = Conv2D(squeeze, (1, 1), padding='valid', name=f_id + 'squeeze1x1')(x)\n",
    "    x = Activation('relu', name=f_id + 'relu_squeeze1x1')(x)\n",
    "\n",
    "    # Expand\n",
    "    left = Conv2D(expand, (1, 1), padding='valid', name=f_id + 'expand1x1')(x)\n",
    "    left = Activation('relu', name=f_id + 'relu_expand1x1')(left)\n",
    "\n",
    "    right = Conv2D(expand, (3, 3), padding='same', name=f_id + 'expand3x3')(x)\n",
    "    right = Activation('relu', name=f_id + 'relu_expand3x3')(right)\n",
    "\n",
    "    x = Concatenate(axis=-1, name=f_id + 'concat')([left, right])\n",
    "    return x\n",
    "\n",
    "def SqueezeNet(input_shape=(224, 224, 3), classes=1000):\n",
    "    img_input = Input(shape=input_shape)\n",
    "\n",
    "    x = Conv2D(64, (3, 3), strides=(2, 2), padding='valid', name='conv1')(img_input)\n",
    "    x = Activation('relu', name='relu_conv1')(x)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool1')(x)\n",
    "\n",
    "    x = fire_module(x, fire_id=2, squeeze=16, expand=64)\n",
    "    x = fire_module(x, fire_id=3, squeeze=16, expand=64)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool3')(x)\n",
    "\n",
    "    x = fire_module(x, fire_id=4, squeeze=32, expand=128)\n",
    "    x = fire_module(x, fire_id=5, squeeze=32, expand=128)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool5')(x)\n",
    "\n",
    "    x = fire_module(x, fire_id=6, squeeze=48, expand=192)\n",
    "    x = fire_module(x, fire_id=7, squeeze=48, expand=192)\n",
    "    x = fire_module(x, fire_id=8, squeeze=64, expand=256)\n",
    "    x = fire_module(x, fire_id=9, squeeze=64, expand=256)\n",
    "\n",
    "    x = Conv2D(classes, (1, 1), padding='valid', name='conv10')(x)\n",
    "    x = Activation('relu', name='relu_conv10')(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Activation('softmax', name='softmax')(x)\n",
    "\n",
    "    model = Model(img_input, x, name='squeezenet')\n",
    "\n",
    "    return model\n",
    "\n",
    "model = SqueezeNet(input_shape=(512, 128, 1), classes=len(label_encoder.classes_))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = to_categorical(y_train)\n",
    "Y_test = to_categorical(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add an extra dimension to the spectrogram data\n",
    "X_train = np.expand_dims(X_train, axis=-1)\n",
    "X_test = np.expand_dims(X_test, axis=-1)\n",
    "\n",
    "# Add an extra dimension to the spectrogram data\n",
    "y_train = np.expand_dims(y_train, axis=-1)\n",
    "y_test = np.expand_dims(y_test, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=3, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize_model(model, save_path, X_train):\n",
    "\n",
    "    def representative_dataset_gen():\n",
    "            for i in range(100):\n",
    "                yield [X_train[i:i + 1]]\n",
    "\n",
    "    # Convert the SavedModel to TensorFlow Lite format\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    converter.representative_dataset = representative_dataset_gen\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS]\n",
    "    converter.inference_input_type = tf.int8\n",
    "    converter.inference_output_type = tf.int8\n",
    "    tflite_model = converter.convert()\n",
    "\n",
    "    # Save the quantized model\n",
    "    with open(save_path, 'wb') as f:\n",
    "        f.write(tflite_model)\n",
    "\n",
    "    return tflite_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qm = quantize_model(model, \"test.tflite\", X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tflite_model_size(tflite_model):\n",
    "    tflite_model_file = Path(\"temp.tflite\")\n",
    "    with tflite_model_file.open(\"wb\") as f:\n",
    "        f.write(tflite_model)\n",
    "    size = tflite_model_file.stat().st_size\n",
    "    tflite_model_file.unlink()\n",
    "    return size\n",
    "\n",
    "#print(get_tflite_model_size(model))\n",
    "print(get_tflite_model_size(qm))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EE595-lab3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
